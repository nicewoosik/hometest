import axios from 'axios'
import fs from 'fs/promises'
import path from 'path'
import { fileURLToPath } from 'url'
import http from 'http'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const BASE_URL = 'http://ecstel.co.kr'
const DIST_DIR = path.join(__dirname, 'dist')

// HTTP agent μ„¤μ •
const httpAgent = new http.Agent({
  keepAlive: true,
  maxSockets: 10
})

async function downloadFile(url, filePath) {
  try {
    const response = await axios.get(url, {
      httpAgent,
      responseType: 'arraybuffer',
      timeout: 30000,
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
      }
    })
    
    await fs.mkdir(path.dirname(filePath), { recursive: true })
    await fs.writeFile(filePath, response.data)
    console.log(`β… λ‹¤μ΄λ΅λ“ μ™„λ£: ${filePath}`)
    return true
  } catch (error) {
    console.error(`β λ‹¤μ΄λ΅λ“ μ‹¤ν¨: ${url} - ${error.message}`)
    return false
  }
}

async function crawlCareerDetail(wrId) {
  console.log('='.repeat(60))
  console.log(`μ±„μ©κ³µκ³  μƒμ„Έ νμ΄μ§€ ν¬λ΅¤λ§ μ‹μ‘: wr_id=${wrId}`)
  console.log('='.repeat(60))
  
  const detailUrl = `${BASE_URL}/NEW/board/bbs/board.php?bo_table=career&wr_id=${wrId}`
  const outputPath = path.join(DIST_DIR, `NEW/board/bbs/board_career_${wrId}.html`)
  
  try {
    console.log(`\nπ“¥ μƒμ„Έ νμ΄μ§€ λ‹¤μ΄λ΅λ“: ${detailUrl}`)
    const response = await axios.get(detailUrl, {
      httpAgent,
      timeout: 30000,
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
      }
    })
    
    let html = response.data
    
    // μƒλ€ κ²½λ΅λ¥Ό μ λ€ κ²½λ΅λ΅ λ³€κ²½
    html = html.replace(/href="\.\.\//g, 'href="/NEW/')
    html = html.replace(/src="\.\.\//g, 'src="/NEW/')
    html = html.replace(/href="\.\//g, 'href="/NEW/board/bbs/')
    html = html.replace(/src="\.\//g, 'src="/NEW/board/bbs/')
    
    // CSS/JS κ²½λ΅ μμ •
    html = html.replace(/href="\/NEW\/css\//g, 'href="/NEW/css/')
    html = html.replace(/href="\/NEW\/js\//g, 'href="/NEW/js/')
    html = html.replace(/src="\/NEW\/js\//g, 'src="/NEW/js/')
    html = html.replace(/src="\/NEW\/images\//g, 'src="/NEW/images/')
    
    // μλ»λ κ²½λ΅ μμ •
    html = html.replace(/href="\/NEW\/bbs\//g, 'href="/NEW/board/bbs/')
    
    await fs.mkdir(path.dirname(outputPath), { recursive: true })
    await fs.writeFile(outputPath, html, 'utf-8')
    console.log(`β… μƒμ„Έ νμ΄μ§€ μ €μ¥ μ™„λ£: ${outputPath}`)
    
  } catch (error) {
    console.error(`β μƒμ„Έ νμ΄μ§€ ν¬λ΅¤λ§ μ‹¤ν¨: ${error.message}`)
  }
  
  console.log('\n' + '='.repeat(60))
  console.log('μƒμ„Έ νμ΄μ§€ ν¬λ΅¤λ§ μ™„λ£')
  console.log('='.repeat(60))
}

// μ±„μ©κ³µκ³  λ©λ΅μ—μ„ λ¨λ“  wr_id μ¶”μ¶
async function crawlAllCareerDetails() {
  const careerIds = [68, 65, 62, 61, 55, 54, 46, 37] // board_career.htmlμ—μ„ ν™•μΈν• IDλ“¤
  
  console.log(`μ΄ ${careerIds.length}κ°μ μƒμ„Έ νμ΄μ§€ ν¬λ΅¤λ§ μ‹μ‘...\n`)
  
  for (const wrId of careerIds) {
    await crawlCareerDetail(wrId)
    // μ„λ²„ λ¶€ν• λ°©μ§€λ¥Ό μ„ν•΄ μ μ‹ λ€κΈ°
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
  
  console.log('\nλ¨λ“  μƒμ„Έ νμ΄μ§€ ν¬λ΅¤λ§ μ™„λ£!')
}

crawlAllCareerDetails().catch(console.error)

